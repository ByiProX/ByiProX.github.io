---
title: 神经网络中为什么不能将权重初始值设置为一样的值
date: 2019-11-04 11:00:31
tags:
  - 机器学习
  - 神经网络
categories:
  - 机器学习
---


先说结论，如果权重初始值设为0的话，将无法正确进行学习。

这是因为在误差反向传播法中，所有的权重值都会进行相同的更新。比如，在2层神经网络中，假设第1层和第2层的权重为0。这样一来，正向传播时，因为输入层的权重为0，所以第2层的神经元全部会被传递相同的值。第2层的神经元中全部输入相同的值，这意味着反向传播时第2层的权重全部都会进行相同的更新。因此，权重被更新为相同的值，并拥有了对称的值(重复的值)。这使得神经网络拥有许多不同的权重的意义丧失了。为了防止“权重均一化” (严格地讲，是为了瓦解权重的对称结构)，必须随机生成初始值。

实际上，考虑一个全连接的神经网络，同一层中的任意神经元是同构的，对于相同的输入他们会有同样的输出，此时如果将参数全部初始化为相同的值，那么无论前向传播还是反向传播，参数的取值还是完全相同，学习将无法打破这种对称性，最终同一网络层中的各个参数仍然是相同的。

综上，必须随机的初始化神经网络参数的值，以打破这种对称性。
