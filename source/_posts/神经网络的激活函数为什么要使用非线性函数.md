---
title: 神经网络的激活函数为什么要使用非线性函数
date: 2019-09-29 10:58:43
tags:
  - 机器学习
  - 神经网络
categories:
  - 机器学习
---
### ▍什么是激活函数
在神经元中，输入的inputs通过加权求和，然后被作用了一个函数，这个函数就是激活函数 `Activation Function`。激活函数在神经网络中的位置如图所示：
![在这里插入图片描述](https://img-blog.csdnimg.cn/20190908231352415.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0MTUyMjQ0,size_16,color_FFFFFF,t_70)

<!-- more -->
###  ▍为什么要用非线性函数
要解释这个问题，可以反过来思考一下，`为什么激活函数不能使用线性函数`。
如果使用线性函数，每一层输出都是上层输入的线性函数，无论神经网络有多少层，输出都是输入的`线性组合`。加深神经网络的层数就没有什么意义了。线性函数的问题在于不管加深层数到多少，总是存在与之等效的`「无隐藏层」`的神经网络。为了稍微直观的理解这一点，考虑下面一个简单的例子。

存在一个线性函数`f(x)=kx(k≠0)`作为激活函数，将`y=f(f(f(x)))`对应三层的神经网络。很明显可以想到同样的处理可以由`y=ax(a=k^3)`，一个没有隐藏层的神经网络来表示。该例子仅仅是一个近似，实际中的神经网络的运算要比这个例子复杂很多，但不影响结论的成立。也就是说，使用线性激活函数时，无法发挥多层网络带来的优势。

相反如果使用非线性函数，激活函数给神经元引入了非线性因素，使得神经网络可以任意逼近任何非线性函数，这样神经网络就可以应用到众多的非线性模型中。

以上！
